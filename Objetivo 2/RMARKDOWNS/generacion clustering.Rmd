---
title: "CLUSTERING GENERACIÓN (OBJETIVO 2)"
author: "Aleixandre"
date: '`r Sys.Date()`'
output:
  html_document:
      runmode: shiny
      toc: true
      number_sections: false
      toc_depth: 2
      toc_float:
        collapsed: false
        smooth_scroll: true
runtime: shiny
---

En este documento, exploraremos la aplicación de técnicas de clustering para analizar los datos de generación energía, dichos datos se encuentran recabados en **df_generacion**, donde se muestra la media de mwh por dia durante ese trimestre para cada comunidad autónoma. El objetivo es agrupar las diferentes comunidades autónomas en función de los valores obtenidos y las distancias entre estos. Al emplear estas técnicas, buscamos identificar patrones y relaciones entre las ccaa, lo que permitirá una mejor comprensión. A lo largo del estudio, examinaremos diversas métricas y algoritmos de clustering, evaluando su efectividad para nuestro conjunto de datos específico, así como estableceremos relaciones con el resto de objetivos del grupo para poder justificar por qué se establecen estos patrones.

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE,echo = TRUE)
```

# **LIBRERÍAS**

```{r, warning=FALSE}
library(ggplot2)
library(readxl)
library(shiny)
library(leaflet)
library(plotly)
library(sf)
library(data.table)
library(tibble)
library(tidyr)
library(reshape2)
library(FactoMineR)
library(factoextra)
library(factoextra)
library(gridExtra)
library(grid)
library(cluster)
library(dbscan)
library(magrittr)
library(dplyr)
library(knitr)
library(clustertend)
library(NbClust)
library(fpc)
library(clValid)
library(kohonen)
library(mapSpain)
library(tidyverse)
library(sf)
library(htmltools)
```

# **PREPARACIÓN BBDD**

Primero, importaremos los archivos que hemos utilizado, los cuales vienen en formato ".csv" y contienen datos de generación y demanda de energía por meses desde 2013 hasta 2023, aunque en este caso solo nos quedaremos con los de generación. Cada archivo representa una comunidad autónoma distinta.

```{r,warning=FALSE}
andalucia = read.csv("DATOS OBJETIVO 2/Andalucía_genvsdem.csv", row.names = 1, as.is = TRUE)
aragon = read.csv("DATOS OBJETIVO 2/Aragón_genvsdem.csv", row.names = 1, as.is = TRUE)
asturias = read.csv("DATOS OBJETIVO 2/Asturias, Principado de_genvsdem.csv", row.names = 1, as.is = TRUE)
baleares = read.csv("DATOS OBJETIVO 2/Balears, Illes_genvsdem.csv", row.names = 1, as.is = TRUE)
canarias = read.csv("DATOS OBJETIVO 2/Canarias_genvsdem.csv", row.names = 1, as.is = TRUE)
cantabria = read.csv("DATOS OBJETIVO 2/Cantabria_genvsdem.csv", row.names = 1, as.is = TRUE)
castillalamancha = read.csv("DATOS OBJETIVO 2/Castilla - La Mancha_genvsdem.csv", row.names = 1, as.is = TRUE)
castillayleon = read.csv("DATOS OBJETIVO 2/Castilla y León_genvsdem.csv", row.names = 1, as.is = TRUE)
cataluña = read.csv("DATOS OBJETIVO 2/Cataluña_genvsdem.csv", row.names = 1, as.is = TRUE)
comunitatValencia = read.csv("DATOS OBJETIVO 2/Comunitat Valenciana_genvsdem.csv", row.names = 1, as.is = TRUE)
extremadura = read.csv("DATOS OBJETIVO 2/Extremadura_genvsdem.csv", row.names = 1, as.is = TRUE)
galicia = read.csv("DATOS OBJETIVO 2/Galicia_genvsdem.csv", row.names = 1, as.is = TRUE)
madrid = read.csv("DATOS OBJETIVO 2/Madrid, Comunidad de_genvsdem.csv", row.names = 1, as.is = TRUE)
murcia = read.csv("DATOS OBJETIVO 2/Murcia, Región de_genvsdem.csv", row.names = 1, as.is = TRUE)
navarra = read.csv("DATOS OBJETIVO 2/Navarra, Comunidad Foral de_genvsdem.csv", row.names = 1, as.is = TRUE)
paisVasco = read.csv("DATOS OBJETIVO 2/País Vasco_genvsdem.csv", row.names = 1, as.is = TRUE)
laRioja = read.csv("DATOS OBJETIVO 2/Rioja, La_genvsdem.csv", row.names = 1, as.is = TRUE)
```

Dado que nuestros datos están organizados por meses, consideramos que sería más conveniente convertirlos en trimestres. Esta decisión se basa en la idea de que la agregación de datos en trimestres facilita la comprensión de las tendencias y patrones , ya que proporciona una vista más general y menos volátil de los datos en comparación con el nivel mensual. Por lo que realizamos una serie de funciones que mostramos a continuación para que se entienda cómo se ha realizado.

```{r,warning=FALSE}
#Esta función la hemos utilizafo para agrupar las observaciones por cada trimestre, pueste que nuestro dataframe inicial contenía los datos de generación y demanda en meses.
agrupar_por_trimestre <- function(datos) {
  # Crear vectores para almacenar los datos agrupados
  datos_agrupadosG <- numeric(length(datos) / 3)
  datos_agrupadosD <- numeric(length(datos) / 3)
  
  # Iterar sobre cada grupo de tres elementos
  for (i in 1:(length(datos_agrupadosG))) {
    # Calcular el índice inicial y final para cada grupo de tres elementos
    indice_inicial <- (i - 1) * 3 + 1
    indice_final <- i * 3
    
    # Calcular la media de los elementos dentro del grupo y almacenar el resultado en los vectores datos_agrupadosG y datos_agrupadosD
    datos_agrupadosG[i] <- sum(datos[1, indice_inicial:indice_final])/3
    datos_agrupadosD[i] <- sum(datos[2, indice_inicial:indice_final])/3
  }
  
  # Crear dataframes individuales para generación y demanda
  df_generacion <- data.frame(datos_agrupadosG)
  df_demanda <- data.frame(datos_agrupadosD)
  
  # Retornar los dataframes individuales
  return(list(Generacion = df_generacion, Demanda = df_demanda))
}

#Utilizada para ponerle el nombre a cada una de las columnas en el formato "añoTtrimestre"

generar_añoTc <- function(año, df) {
  # Inicializar la lista para almacenar los valores de añoTc en el formato deseado
  lista <- c()
  
  # Iterar sobre las columnas del dataframe
  for (i in 1:dim(df)[2]) {
    # Verificar si el índice es un múltiplo de 4 (excepto el primero)
    if (i %% 4 == 1 & i != 1) {
      año <- año + 1
    }
    # Calcular el trimestre
    trimestre <- (i %% 4)
    if (trimestre == 0){
      trimestre = 4
    }
    # Agregar el valor en el formato deseado a la lista
    lista <- c(lista, paste(año, "T", trimestre, sep = ""))
  }
  
  # Retornar la lista resultante
  return(lista)
}

# Definir la función
plot_medias_generacion_produccion <- function(df_generacion_o) {
  # Calcular las medias de cada fila
  medias_d <- rowMeans(df_generacion_o, na.rm = TRUE)
  
  # Calcular la media general
  media_general_d <- mean(medias_d)
  
  # Graficar las medias ordenadas en un gráfico de barras
  barplot(medias_d[order(medias_d, decreasing = TRUE)], las = 2, main = "Medias generación producción")
  
  # Añadir una línea horizontal en la media general
  abline(h = media_general_d, col = "red")
  
  # Retornar los valores calculados en una lista
  return(list(medias_individuales = medias_d, media_general = media_general_d))
}
```

En el siguiente fragmento de código, hemos implementado funciones para procesar los datos de cada archivo de cada comunidad. Estas funciones se encargan de agrupar los datos por generación y por demanda en dataframes separados, aunque en este caso solo nos quedaremos con GENERACIÓN..

```{r,warning=FALSE,include=FALSE}
#Realizamos la agrupación por trimestres en cada CCAA
randalucia = agrupar_por_trimestre(andalucia)
raragon = agrupar_por_trimestre(aragon)
rasturias = agrupar_por_trimestre(asturias)
rbaleares = agrupar_por_trimestre(baleares)
rcanarias = agrupar_por_trimestre(canarias)
rcantabria = agrupar_por_trimestre(cantabria)
rcyl = agrupar_por_trimestre(castillalamancha)
rcyleon = agrupar_por_trimestre(castillayleon)
rcat = agrupar_por_trimestre(cataluña)
rcv = agrupar_por_trimestre(comunitatValencia)
re = agrupar_por_trimestre(extremadura)
rg = agrupar_por_trimestre(galicia)
rm = agrupar_por_trimestre(madrid)
rmur = agrupar_por_trimestre(murcia)
rnav = agrupar_por_trimestre(navarra)
rpv = agrupar_por_trimestre(paisVasco)
rlR = agrupar_por_trimestre(laRioja)


#Separamos los datos de los dataframes anteriores quedándonos únicamente con los de GENERACIÓN
generacion_por_region <- list(
  randalucia$Generacion,
  raragon$Generacion,
  rasturias$Generacion,
  rbaleares$Generacion,
  rcanarias$Generacion,
  rcantabria$Generacion,
  rcyl$Generacion,
  rcyleon$Generacion,
  rcat$Generacion,
  rcv$Generacion,
  re$Generacion,
  rg$Generacion,
  rm$Generacion,
  rmur$Generacion,
  rnav$Generacion,
  rpv$Generacion,
  rlR$Generacion
)

# Crear un dataframe con una columna que contiene los dataframes de generación por región
df_generacion <- data.frame(Generacion = generacion_por_region)

# Imprimir el dataframe
df_generacion <- t(df_generacion)

row.names(df_generacion) <-  c(
  "Andalucia", "Aragon", "Principado de Asturias", "Illes Balears", "Canarias",
  "Cantabria", "Castilla - La Mancha", "Castilla y Leon", "Cataluña",
  "Comunitat Valenciana", "Extremadura", "Galicia", "Madrid",
  "Murcia", "Navarra", "Pais Vasco", "La Rioja"
)


col_n  = generar_añoTc(2013,df_generacion)
colnames(df_generacion) <- col_n

```

# **CLUSTERING**

Comenzaremos aplicando la técnica de clustering. Inicialmente, consideramos que usar distancias basadas en la correlación sería apropiado. Sin embargo, después de varios intentos, observamos que la métrica de Silhouette resultaba negativa, lo que indicaba una mala clasificación. Tras reflexionar sobre ello, concluimos que esto podría ser debido a la estacionalidad, ya que las variables podrían estar altamente correlacionadas entre sí.

Por lo tanto, decidimos optar por medidas de distancias, como la distancia euclídea y la de Manhattan, lo que nos permitiría agrupar en función de las diferencias entre los valores. Esto tendría sentido, ya que las CCAA con valores más similares estarían agrupadas entre sí.

Primero, calcularemos las matrices de distancias utilizando estas dos métricas diferentes.

```{r,warning=FALSE}
df_generacion_o = df_generacion
df_generacion = scale(df_generacion, center = TRUE, scale = FALSE)

```

```{r,warning=FALSE}
midist_euclidean <- get_dist(df_generacion, stand = FALSE, method = "euclidean")
fviz_dist(midist_euclidean, show_labels = TRUE, lab_size = 0.3,
          gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

```{r,warning=FALSE}
midist <- get_dist(df_generacion, stand = FALSE, method = "manhattan")
fviz_dist(midist, show_labels = TRUE, lab_size = 0.3,
          gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))
```

Después de generar los mapas de calor para las distancias utilizando tanto la distancia euclidiana como la de Manhattan, observamos que ambos muestran 4-5 clústeres distintos, ya que podemos identificar en función de quién lo observe estos números de "cuadrados" de color azul diferenciados. Además, en ambos casos, las observaciones están bastante cerca del centro.

Dado que hemos obtenido resultados bastante similares en la representación de las distancias, hemos decidido utilizar la distancia euclidiana para continuar con nuestro análisis.

```{r,warning=FALSE}
set.seed(100)
myN = c(4, 8, 12)  # m
myhopkins = NULL
myseed = sample(1:1000, 10)
for (i in myN) {
  for (j in myseed) {
    tmp = get_clust_tendency(data = df_generacion, n = i, graph = FALSE, seed = j)
    myhopkins = c(myhopkins, tmp$hopkins_stat)
  }
}
summary(myhopkins)
```

El estadístico de Hopkins nos confirma una cierta tendencia de agrupamiento, puesto que ha sido calculado para diferentes valores de m (n en la función) y con diferentes semillas aleatorias y sus valores oscilan entre 0.6252 y 0.8748, es decir, están cercanos a 1.

Ahora realizaremos una serie de modelos para realizar los agrupamientos, y luego realizaremos una validación para elegir el mejor de todos ellos.

## Modelos jerárquicos

#### Método de Ward

```{r,warning=FALSE}
p1 = fviz_nbclust(x = df_generacion, FUNcluster = hcut, method = "silhouette", 
                  hc_method = "ward.D2", k.max = 10, verbose = FALSE, 
                  hc_metric = "euclidean") + labs(title = "Num. optimo clusters")
p2 = fviz_nbclust(x = df_generacion, FUNcluster = hcut, method = "wss", 
                  hc_method = "ward.D2", k.max = 10, verbose = FALSE, 
                  hc_metric = "euclidean") + labs(title = "Num. optimo clusters")
grid.arrange(p1, p2, nrow = 1)
```

Después de analizar tanto el gráfico de Silhouette como el de la variabilidad intra-cluster, hemos llegado a la conclusión de que el número óptimo de clústeres es 4. A pesar de que el valor de Silhouette para 4 clústeres es ligeramente inferior al valor máximo obtenido con 2 clústeres, sigue siendo suficientemente alto, indicando una buena separación entre los clústeres. Además, el análisis de la variabilidad intra-cluster muestra una distancia intra-cluster muy baja para 4 clústeres, lo que sugiere que los puntos dentro de cada clúster están muy cerca entre sí, reflejando una alta cohesión.

Asimismo, al aplicar la regla del codo en el gráfico de la variabilidad intra-cluster, observamos que la reducción en la variabilidad se estabiliza alrededor de 4 clústeres. Esto respalda nuestra elección, ya que más allá de este punto, agregar más clústeres no proporciona una mejora significativa en términos de variabilidad explicada. En resumen, la elección de 4 clústeres ofrece un buen equilibrio entre la separación clara de los clústeres y una alta cohesión dentro de ellos, lo que justifica esta decisión como la más adecuada.

Esta tabla nos sirve para conocer cómo se distribuyen las observaciones en cada clúster, en ella podemos observar que el grupo 3 tiene un mayor número de observaciones que el resto.

```{r,warning=FALSE}
clust1 <- hclust(midist_euclidean, method="ward.D2")
grupos1 <- cutree(clust1, k=4)
table(grupos1)
```

A continuación, realizaremos el dendograma que nos ofrece la estructura de los datos y cómo se pueden separar, de una forma más visual y simple:

```{r,warning=FALSE}
fviz_dend(clust1, k = 4,
          cex = 0.5, color_labels_by_k = TRUE,
          rect = TRUE) # dibujar rectángulos
```

Al visualizar nuestros datos en el dendograma, también observamos que la representación de los clusters coincide bien con el número de 4 clusters que hemos identificado anteriormente. Esta concordancia refuerza nuestra confianza en la elección del número óptimo de clusters para nuestro análisis, pese a ello probaremos también con 3 y veremos cuál nos ofrece una mejor separación.

A continuación, realizaremos la representación de los clusters en un gráfico de scores de un PCA, esto nos ayudará a entender cómo están distribuidas.

```{r,warning=FALSE}
fviz_cluster(object = list(data=df_generacion, cluster=grupos1), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8)  +
  labs(title = "Modelo jerarquico + Proyeccion PCA",
       subtitle = "Dist euclidea, Metodo Ward, K=4>") +
  theme_bw() +
  theme(legend.position = "bottom")

fviz_cluster(object = list(data=df_generacion, cluster=grupos1), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8,axes = 3:4)  +
  labs(title = "Modelo jerarquico + Proyeccion PCA",
       subtitle = "Dist euclidea, Metodo Ward, K=4>") +
  theme_bw() +
  theme(legend.position = "bottom")

resultados <- plot_medias_generacion_produccion(df_generacion_o)


```

Después de crear el gráfico de scores para las dimensiones 1 y 2, podemos observar que los clusters están claramente diferenciados. Específicamente, la dimensión 1 contiene el 94.5% de la variabilidad, lo que indica que es la dimensión principal y que es suficiente para representar los clústeres de manera efectiva. Todo lo que vamos explicando queda reflejado en el barplot que hemos creado, donde la línea roja representa la media de valores de generación.

Al analizar los clústeres, notamos que el cluster número 3 tiene un gran número de observaciones y además se encuentran muy concentradas entre ellas, sin haber una gran separación. Por otra parte al observar el dataframe de generación y el gráfico de medias podemos ver que estas observaciones corresponden a las CCAA con un valor más bajo respecto a la producción por lo que podríamos clasificar este cluster como el de observaciones con menor producción, pese a que den un valor positivo respecto al resto, ya que esto último se debe al software, y al utilizar la función fviz_pca_ind obtendríamos este como negativo.

Por otro lado tenemos el clúster 2, que se trata de las siguientes comunidades con unavproducción superior a la media, es por ello por lo que supera el 0, que es la media obtenida al escalar, sin embargo se encuentan alejadas de los valores más altos de producción, esto también lo podemos relacionar con la extensión del territorio y con el tipo de energía de mayor producida en cada territorio.

El clúster número 4 incluye observaciones con un valor superior a la media, específicamente de las comunidades autónomas de Castilla y León y Galicia. Estas comunidades se destacan por su alta producción en energías renovables, como la fotovoltaica, eólica e hidráulica, combinadas con otros tipos de energías como la termodinámica. Esta diversidad energética contribuye a que sean de las regiones con mayor producción energética.

Castilla y León, en particular, posee una gran extensión de terreno, lo cual favorece el desarrollo y la expansión de estas fuentes de energía renovable. Además, podemos relacionar su alto valor de producción energética con la época fría del año, es decir, el invierno. Durante el invierno, las bajas temperaturas incrementan la demanda de energía, lo que requiere una alta producción para satisfacer las necesidades energéticas de la población.

Cataluña y Andalucía destacan por su alta producción energética debido a varios factores clave. Cataluña cuenta con diversas fuentes de energía, incluyendo nucleares, hidráulicas y renovables, apoyadas por una infraestructura eficiente y una fuerte base industrial. Andalucía lidera en energía solar y eólica, gracias a su alta radiación solar y extensos terrenos que facilitan grandes parques energéticos. Ambas regiones se benefician de políticas favorables y subsidios que han incentivado inversiones significativas en energías renovables. La alta demanda energética, impulsada por sus grandes poblaciones y economías diversificadas, también contribuye a estos altos niveles de producción. En conjunto, estos factores permiten a Cataluña y Andalucía mantener una producción energética elevada y sostenible, satisfaciendo tanto la demanda local como nacional.

#### Método de Medias

```{r,warning=FALSE}
p1 = fviz_nbclust(x = df_generacion, FUNcluster = hcut, method = "silhouette", 
                  hc_method = "average", k.max = 10, verbose = FALSE, 
                  hc_metric = "euclidean") + labs(title = "Num. optimo clusters")
p2 = fviz_nbclust(x = df_generacion, FUNcluster = hcut, method = "wss", 
                  hc_method = "average", k.max = 10, verbose = FALSE, 
                  hc_metric = "euclidean") + labs(title = "Num. optimo clusters")
grid.arrange(p1, p2, nrow = 1)
```

```{r,warning=FALSE}
clust2 <- hclust(midist_euclidean, method="average")
grupos2 = cutree(clust2, k = 5)
fviz_dend(clust2, k = 5,
          cex = 0.5,
          color_labels_by_k = TRUE, # colorear etiquetas por grupo
          rect = TRUE) # dibujar rectángulos
```

```{r,warning=FALSE}
fviz_cluster(object = list(data=df_generacion, cluster=grupos2), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8)  +
  labs(title = "Modelo jerarquico + Proyeccion PCA",
       subtitle = "Dist euclidea, Metodo Ward, K=5>") +
  theme_bw() +
  theme(legend.position = "bottom")

fviz_cluster(object = list(data=df_generacion, cluster=grupos2), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8,axes = 3:4)  +
  labs(title = "Modelo jerarquico + Proyeccion PCA",
       subtitle = "Dist euclidea, Metodo Ward, K=5>") +
  theme_bw() +
  theme(legend.position = "bottom")
```

Ahora realizaremos los métodos de partición: En primer lugar lo realizaremos para k-medias

## Métodos Partición

#### Método de Kmeans

```{r,warning=FALSE}
p1 = fviz_nbclust(x = df_generacion, FUNcluster = kmeans, method = "silhouette", 
             k.max = 10, verbose = FALSE) +
  labs(title = "K-means")
p2 = fviz_nbclust(x = df_generacion, FUNcluster = kmeans, method = "wss", 
             k.max = 10, verbose = FALSE) +
  labs(title = "K-means")
grid.arrange(p1, p2, nrow = 1)
```

```{r,warning=FALSE}
set.seed(100)
clust3 <- kmeans(df_generacion, centers = 5, nstart = 20)
table(clust3$cluster)

```

```{r,warning=FALSE}
p1 = fviz_cluster(object = list(data=df_generacion, cluster=clust3$cluster), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8)  +
  labs(title = "K-MEDIAS + Proyeccion PCA",
       subtitle = "Dist euclidea, K=5") +
  theme_bw() +
  theme(legend.position = "bottom")
p2 = fviz_cluster(object = list(data=df_generacion, cluster=clust3$cluster), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8, axes = 3:4)  +
  labs(title = "K-MEDIAS + Proyeccion PCA",
       subtitle = "Dist euclidea, K=5") +
  theme_bw() +
  theme(legend.position = "bottom")
grid.arrange(p1, p2, nrow = 1)
```

#### Método de k-medoides

```{r,warning=FALSE}
p1 = fviz_nbclust(x = df_generacion, FUNcluster = pam, method = "silhouette", 
             k.max = 10, verbose = FALSE) +
  labs(title = "Numero optimo de clusters")
p2 = fviz_nbclust(x = df_generacion, FUNcluster = pam, method = "wss", 
             k.max = 10, verbose = FALSE) +
  labs(title = "Numero optimo de clusters")
grid.arrange(p1, p2, nrow = 1)
```

```{r,warning=FALSE}
clust4 <- pam(df_generacion, k = 5)
table(clust4$clustering)
```

```{r,warning=FALSE}
fviz_cluster(object = list(data=df_generacion, cluster=clust4$clustering), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8)  +
  labs(title = "K-MEDOIDES + Proyeccion PCA",
       subtitle = "Dist euclidea, K=5") +
  theme_bw() +
  theme(legend.position = "bottom")
fviz_cluster(object = list(data=df_generacion, cluster=clust4$clustering), stand = FALSE,
             ellipse.type = "convex", geom = "text", show.clust.cent = FALSE,
             labelsize = 8, axes = 3:4)  +
  labs(title = "K-MEDOIDES + Proyeccion PCA",
       subtitle = "Dist euclidea, K=5") +
  theme_bw() +
  theme(legend.position = "bottom")

```

## Selección y validación de modelos

```{r,warning=FALSE}
# Establecer el diseño de la grilla de gráficos
par(mfrow = c(1,3))

# Graficar coeficientes de silueta para Ward
plot(silhouette(grupos1, midist_euclidean), col = rainbow(4), border = NA, main = "WARD")

# Graficar coeficientes de silueta para K-MEDIAS
plot(silhouette(clust3$cluster, midist_euclidean), col = rainbow(5), border = NA, main = "K-MEDIAS")

# Graficar coeficientes de silueta para K-MEDOIDES
plot(silhouette(clust4$clustering, midist_euclidean), col = rainbow(5), border = NA, main = "K-MEDOIDES")
```

Tras realizar la selección del modelo decidimos quedarnos con el método de ward, ya que el valor obtenido por este es superior al resto y por tanto es el mejor teniendo en cuenta este aspecto.

## PCA

A continuación, realizaremos la representación PCA para conocer mejor por qué se distribuyen de tal forma las dimensiones

```{r,warning=FALSE}
misclust = factor(clust3$cluster)
miPCA = PCA(df_generacion, scale.unit = FALSE, graph = FALSE)
eig.val = get_eigenvalue(miPCA)
Vmedia = 100 * (1/nrow(eig.val))
fviz_eig(miPCA, addlabels = TRUE) +
  geom_hline(yintercept=Vmedia, linetype=2, color="red")
```

```{r,warning=FALSE}
p1 = fviz_pca_ind(miPCA, geom = "point", habillage = misclust, addEllipses = FALSE)
p2 = fviz_pca_var(miPCA)
grid.arrange(p1, p2, nrow = 1)
```

Es interesante notar cómo todas las variables están representadas predominantemente en la dimensión 1, lo que sugiere que esta dimensión captura la mayor parte de la variabilidad en los datos. Aunque algunas variables pueden tener cierta inclinación en la dimensión 2, su contribución a la variabilidad total es mucho menor, como lo indica el 3.1% de variabilidad explicada por la dimensión 2.

Esta observación resalta la importancia de la dimensión 1 en la representación de los datos y sugiere que la mayoría de las diferencias entre las observaciones están capturadas por esta dimensión principal.

```{r,warning=FALSE}
# Calcular medias por clúster
mediasCluster <- aggregate(df_generacion, by = list("cluster" = misclust), mean)[,-1]

# Establecer nombres de fila
rownames(mediasCluster) <- paste0("c", seq_len(nrow(mediasCluster)))

# Mostrar los resultados
kable(t(round(mediasCluster, 2)))

```

```{r,warning=FALSE}
matplot(t(mediasCluster), type = "l", col = rainbow(5), ylab = "", xlab = "", lwd = 2,
        lty = 1, main = "Perfil medio de los clusters", xaxt = "n")
axis(side = 1, at = 1:ncol(df_generacion), labels = colnames(df_generacion), las = 2)
legend("topleft", as.character(1:5), col = rainbow(5), lwd = 2, ncol = 3, bty = "n")
```

El gráfico muestra la evolución temporal del perfil medio de cinco clusters desde el primer trimestre de 2013 hasta el tercer trimestre de 2023. Cada cluster está representado por una línea de color diferente: el cluster 1 (rojo) es bastante estable, el cluster 2 (verde) muestra variaciones moderadas con una ligera tendencia al alza, el cluster 3 (azul) es el más estable con pocas variaciones, el cluster 4 (amarillo) presenta mayores fluctuaciones con picos y valles pronunciados, y el cluster 5 (morado) tiene la mayor amplitud de variación con tendencias cíclicas marcadas. El eje y indica la magnitud de los perfiles medios, mientras que el eje x representa los trimestres a lo largo de los años, permitiendo visualizar patrones de comportamiento, estabilidad y variaciones dentro de cada grupo a lo largo del tiempo.

## Representación Mapa de España

Ahora lo que vamos a hacer es una representación del mejor método en un mapa de España, donde aparecerán las diferentes CCAA coloreadas en función del cluster al que pertenecen. De este modo será más visual y entendible cada una de las conclusiones que hemos ido extrayendo en los anteriores apartados.

```{r}
datos = as.data.frame(grupos1)

ccaa2 = c("Andalucía", "Aragón", "Asturias, Principado de", "Balears, Illes", "Canarias", "Cantabria", "Castilla - La Mancha", "Castilla y León", "Cataluña", "Comunitat Valenciana", "Extremadura", "Galicia", "Madrid, Comunidad de", "Murcia, Región de", "Navarra, Comunidad Foral de", "País Vasco", "Rioja, La")

rownames(datos)<- NULL
datos <- cbind(datos,ccaa2)
```

```{r,warning=FALSE}


#Qué diferencias hay entre cada 
#Extreaemos la información necesaria para poder hacer el mapa de España con figuras
#gracias a la función esp_get_ccaa() de la librería mapSpain. En el dataframe obtenido
#tenemos la columna geometry que es con la que plotearemos la geografía española
ccaa <- esp_get_ccaa()
ccaa <- ccaa[,c("ine.ccaa.name", "geometry")]
#Como también incluye Canarias, sacamos una cajita que las contenga 
#para que quede mejor el gráfico
can_box <- esp_get_can_box()

ceuta_melilla = data.frame(
  grupos1 = c(NA,NA),
  ccaa2 = c("Ceuta", "Melilla")
)

datos <- rbind(datos, ceuta_melilla)

ui <- fluidPage(
  titlePanel("Clusters para generación por ccaa"),
    mainPanel(
      # Agregar el gráfico del mapa
      plotlyOutput("map_plot")
    )
  )


server <- function(input, output) {
  output$map_plot <- renderPlotly({
    ccaa <- merge(ccaa, datos, by.x = "ine.ccaa.name", by.y = "ccaa2", all.x = TRUE)
    # Crear el mapa de España con Plotly
    p <- ggplot(ccaa) +
      geom_sf(aes(fill = factor(grupos1)), color = NA) +  # Eliminar las líneas de los polígonos
      scale_fill_manual(values = c("1" = "#4E79A7",
"2" = "#6EB5A2",
"3" = "#A18F7E",
"4" = "#84A390"),name="Clusters") +  # Definir colores manuales
      geom_sf_text(aes(label = ine.ccaa.name), size = 2, color = "black") +
      geom_sf(data = can_box, inherit.aes = FALSE) +
      theme_void() +  # Eliminar grados y otros elementos de los ejes
      theme(legend.position = "bottom")  # Opcional: Colocar la leyenda en la parte inferior
    
    # Convertir el objeto ggplot a un gráfico interactivo de Plotly
    ggplotly(p)
  })
}
shinyApp(ui = ui, server = server)
```
